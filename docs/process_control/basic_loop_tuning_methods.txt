Top of FormBottom of Form1: PID Tuning1.1: IntroductionCurrently, more than half of the controllers used in industry are PID controllers. In the past, many of these controllers were analog; however, many of today's controllers use digital signals and computers. When a mathematical model of a system is available, the parameters of the controller can be explicitly determined. However, when a mathematical model is unavailable, the parameters must be determined experimentally. Controller tuning is the process of determining the controller parameters which produce the desired output. Controller tuning allows for optimization of a process and minimizes the error between the variable of the process and its set point.Types of controller tuning methods include the trial and error method, and process reaction curve methods. The most common classical controller tuning methods are the Ziegler-Nichols and Cohen-Coon methods. These methods are often used when the mathematical model of the system is not available. The Ziegler-Nichols method can be used for both closed and open loop systems, while Cohen-Coon is typically used for open loop systems. A closed-loop control system is a system which uses feedback control. In an open-loop system, the output is not compared to the input.The equation below shows the PID algorithm as discussed in the previous PID Control section.??(??)=????(??(??)+1????∫??0??(???)?????+????????(??)????)+??where* u is the control signal* ? is the difference between the current value and the set point.* Kc is the gain for a proportional controller.* ?i is the parameter that scales the integral controller.* ?d is the parameter that scales the derivative controller.* t is the time taken for error measurement.* b is the set point value of the signal, also known as bias or offset.The experimentally obtained controller gain which gives stable and consistent oscillations for closed loop systems, or the ultimate gain, is defined as Ku . Kc is the controller gain which has been corrected by the Ziegler-Nichols or Cohen-Coon methods, and can be input into the above equation. Ku is found experimentally by starting from a small value of Kc and adjusting upwards until consistent oscillations are obtained, as shown below. If the gain is too low, the output signal will be damped and attain equilibrium eventually after the disturbance occurs as shown below.On the other hand, if the gain is too high, the oscillations become unstable and grow larger and larger with time as shown below.The process reaction curve method section shows the parameters required for open loop system calculations. The Ziegler-Nichols Method section shows how to find Kc, Ti, and Td for open and closed loop systems, and the Cohen-Coon section shows an alternative way to find Kc, Ti, and Td.Open loop systems typically use the quarter decay ratio (QDR) for oscillation dampening. This means that the ratio of the amplitudes of the first overshoot to the second overshoot is 4:1.1.1.1: Trial and ErrorThe trial and error tuning method is based on guess-and-check. In this method, the proportional action is the main control, while the integral and derivative actions refine it. The controller gain, Kc, is adjusted with the integral and derivative actions held at a minimum, until a desired output is obtained.Below are some common values of Kc, Ti, and Td used in controlling flow, levels, pressure or temperature for trial and error calculations.1.1.1.1: FlowP or PI control can be used with low controller gain. Use PI control for more accuracy with high integration activity. Derivative control is not considered due to the rapid fluctuations in flow dynamics with lots of noise.Kc = 0.4-0.65Ti = 6s1.1.1.2: LevelP or PI control can be used, although PI control is more common due to inaccuracies incurred due to offsets in P-only control. Derivative control is not considered due to the rapid fluctuations in flow dynamics with lots of noise.The following P only setting is such that the control valve is fully open when the vessel is 75% full and fully closed when 25% full, being half open when 50% filled.Kc = 2Bias b = 50%Set point = 50%For PI control:Kc = 2-20Ti = 1-5 min1.1.1.3: PressureTuning here has a large range of possible values of Kc and Ti for use in PI control, depending on if the pressure measurement is in liquid or gas phase.LiquidKc = 0.5-2Ti = 6-15 sGasKc = 2-10Ti = 2-10 min1.1.1.4: TemperatureDue to the relatively slow response of temperature sensors to dynamic temperature changes, PID controllers are used.Kc = 2-10Ti = 2-10 minTd = 0-5 min1.1.2: Process Reaction CurveIn this method, the variables being measured are those of a system that is already in place. A disturbance is introduced into the system and data can then be obtained from this curve. First the system is allowed to reach steady state, and then a disturbance, Xo, is introduced to it. The percentage of disturbance to the system can be introduced by a change in either the set point or process variable. For example, if you have a thermometer in which you can only turn it up or down by 10 degrees, then raising the temperature by 1 degree would be a 10% disturbance to the system. These types of curves are obtained in open loop systems when there is no control of the system, allowing the disturbance to be recorded. The process reaction curve method usually produces a response to a step function change for which several parameters may be measured which include: transportation lag or dead time, ?dead, the time for the response to change, ?, and the ultimate value that the response reaches at steady-state, Mu.?dead = transportation lag or dead time: the time taken from the moment the disturbance was introduced to the first sign of change in the output signal? = the time for the response to occurXo = the size of the step changeMu = the value that the response goes to as the system returns to steady-state??=??dead??????=????????????deadAn example for determining these parameters for a typical process response curve to a step change is shown below.In order to find the values for ?dead and ?, a line is drawn at the point of inflection that is tangent to the response curve and then these values are found from the graph.To map these parameters to P,I, and D control constants, see Table 2 and 3 below in the Z-N and Cohen Coon sections.1.2: Ziegler-Nichols MethodIn the 1940's, Ziegler and Nichols devised two empirical methods for obtaining controller parameters. Their methods were used for non-first order plus dead time situations and involved intense manual calculations. With improved optimization software, most manual methods such as these are no longer used. However, even with computer aids, the following two methods are still employed today, and are considered among the most common:1.2.1: Ziegler-Nichols closed-loop tuning methodThe Ziegler-Nichols closed-loop tuning method allows you to use the ultimate gain value, Ku, and the ultimate period of oscillation, Pu, to calculate Kc . It is a simple method of tuning PID controllers and can be refined to give better approximations of the controller. You can obtain the controller constants Kc , Ti , and Td in a system with feedback. The Ziegler-Nichols closed-loop tuning method is limited to tuning processes that cannot run in an open-loop environment.Determining the ultimate gain value, Ku, is accomplished by finding the value of the proportional-only gain that causes the control loop to oscillate indefinitely at steady state. This means that the gains from the I and D controller are set to zero so that the influence of P can be determined. It tests the robustness of the Kc value so that it is optimized for the controller. Another important value associated with this proportional-only control tuning method is the ultimate period (Pu). The ultimate period is the time required to complete one full oscillation while the system is at steady state. These two parameters, Ku and Pu, are used to find the loop-tuning constants of the controller (P, PI, or PID). To find the values of these parameters, and to calculate the tuning constants, use the following procedure:Closed Loop (Feedback Loop)1. Remove integral and derivative action. Set integral time (Ti) to 999 or its largest value and set the derivative controller (Td) to zero.2. Create a small disturbance in the loop by changing the set point. Adjust the proportional, increasing and/or decreasing, the gain until the oscillations have constant amplitude.3. Record the gain value (Ku) and period of oscillation (Pu).Figure 1. System tuned using the Ziegler-Nichols closed-loop tuning method4. Plug these values into the Ziegler-Nichols closed loop equations and determine the necessary settings for the controller.Table 1. Closed-Loop Calculations of Kc, Ti, TdAdvantages1. Easy experiment; only need to change the P controller2. Includes dynamics of whole process, which gives a more accurate picture of how the system is behavingDisadvantages1. Experiment can be time consuming2. Can venture into unstable regions while testing the P controller, which could cause the system to become out of control1.2.2: Ziegler-Nichols Open-Loop Tuning Method or Process Reaction MethodThis method remains a popular technique for tuning controllers that use proportional, integral, and derivative actions. The Ziegler-Nichols open-loop method is also referred to as a process reaction method, because it tests the open-loop reaction of the process to a change in the control variable output. This basic test requires that the response of the system be recorded, preferably by a plotter or computer. Once certain process response values are found, they can be plugged into the Ziegler-Nichols equation with specific multiplier constants for the gains of a controller with either P, PI, or PID actions.Open Loop (Feed Forward Loop)To use the Ziegler-Nichols open-loop tuning method, you must perform the following steps:1. Make an open loop step test2. From the process reaction curve determine the transportation lag or dead time, ?dead, the time constant or time for the response to change, ?, and the ultimate value that the response reaches at steady-state, Mu, for a step change of Xo.3. Determine the loop tuning constants. Plug in the reaction rate and lag time values to the Ziegler-Nichols open-loop tuning equations for the appropriate controller—P, PI, or PID—to calculate the controller constants. Use the table below.Table 2. Open-Loop Calculations of Kc, Ti, TdAdvantages1. Quick and easier to use than other methods2. It is a robust and popular method3. Of these two techniques, the Process Reaction Method is the easiest and least disruptive to implementDisadvantages1. It depends upon purely proportional measurement to estimate I and D controllers.2. Approximations for the Kc, Ti, and Td values might not be entirely accurate for different systems.3. It does not hold for I, D and PD controllers1.3: Cohen-Coon MethodThe Cohen-Coon method of controller tuning corrects the slow, steady-state response given by the Ziegler-Nichols method when there is a large dead time (process delay) relative to the open loop time constant; a large process delay is necessary to make this method practical because otherwise unreasonably large controller gains will be predicted. This method is only used for first-order models with time delay, due to the fact that the controller does not instantaneously respond to the disturbance (the step disturbance is progressive instead of instantaneous).The Cohen-Coon method is classified as an 'offline' method for tuning, meaning that a step change can be introduced to the input once it is at steady-state. Then the output can be measured based on the time constant and the time delay and this response can be used to evaluate the initial control parameters.For the Cohen-Coon method, there are a set of pre-determined settings to get minimum offset and standard decay ratio of 1/4(QDR). A 1/4(QDR) decay ratio refers to a response that has decreasing oscillations in such a manner that the second oscillation will have 1/4 the amplitude of the first oscillation . These settings are shown in Table 3..Table 3. Standard recommended equations to optimize Cohen Coon predictionswhere the variables P, N, and L are defined below.Alternatively, K0 can be used instead of (P/NL). K0,?, and ?dead are defined in process reaction curve section. An example using these parameters is shown here [1].The process in Cohen-Coon turning method is the following:1. Wait until the process reaches steady state.2. Introduce a step change in the input.3. Based on the output, obtain an approximate first order process with a time constant ? delayed by ?dead units from when the input step was introduced.The values of ? and ?dead can be obtained by first recording the following time instances:t0 = time at input step start point t2 = time when reaches half point t3 = time when reaches 63.2% point4. Using the measurements at t0, t2, t3, A and B, evaluate the process parameters ?, ?dead, and Ko.5. Find the controller parameters based on ?, ?dead, and Ko.Advantages1. Used for systems with time delay.2. Quicker closed loop response time.Disadvantages and Limitations1. Unstable closed loop systems.2. Can only be used for first order models including large process delays.3. Offline method.4. Approximations for the Kc, ?i, and ?d values might not be entirely accurate for different systems.Other MethodsThese are other common methods that are used, but they can be complicated and aren't considered classical methods, so they are only briefly discussed.1.3: Internal Model ControlThe Internal Model Control (IMC) method was developed with robustness in mind. The Ziegler-Nichols open loop and Cohen-Coon methods give large controller gain and short integral time, which isn't conducive to chemical engineering applications. The IMC method relates to closed-loop control and doesn't have overshooting or oscillatory behavior. The IMC methods however are very complicated for systems with first order dead time.Auto Tune VariationThe auto-tune variation (ATV) technique is also a closed loop method and it is used to determine two important system constants (Pu and Ku for example). These values can be determined without disturbing the system and tuning values for PID are obtained from these. The ATV method will only work on systems that have significant dead time or the ultimate period, Pu, will be equal to the sampling period.1.4: Example01      You're a controls engineer working for Flawless Design company when your optimal controller breaks down. As a backup, you figure that by using coarse knowledge of a classical method, you may be able to sustain development of the product. After adjusting the gain to one set of data taken from a controller, you find that your ultimate gain is 4.3289.From the adjusted plot below, determine the type of loop this graph represents; then, please calculate Kc, Ti, and Td for all three types of controllers.SolutionFrom the fact that this graph oscillates and is not a step function, we see that this is a closed loop. Thus, the values will be calculated accordingly.We're given the Ultimate gain, Ku = 4.3289. From the graph below, we see that the ultimate period at this gain is Pu = 6.28From this, we can calculate the Kc, Ti, and Td for all three types of controllers. The results are tabulated below. (Results were calculated from the Ziegler-Nichols closed-loop equations.)1.5: Example02Your partner finds another set of data after the controller breaks down and decides to use the Cohen-Coon method because of the slow response time for the system. They also noticed that the control dial, which goes from 0-8, was set at 3 instead of 1. Luckily the response curve was obtained earlier and is illustrated below. From this data he wanted to calculate Kc, Ti and Td. Help him to determine these values. Note that the y-axis is percent change in the process variable.SolutionIn order to solve for Kc, Ti and Td, you must first determine L, ?Cp, and T. All of these values may be calculated by the reaction curve given.From the process reaction curve we can find that:??=3??=11\(?C_p = 0.55\, (55%)\)Now that these three values have been found N and R may be calculated using the equations below.N = ∆Cp/TR = L/T = NL/∆CpUsing these equations, you find thatN = .05R = 0.27We also know that since the controller was moved from 1 to 3, so a 200% change.P = 2.00We use these values to calculate Kc, Ti, and Td, for the three types of controllers based on the equations found in Table 3.2.1: Tuning the parameters of a PID controller on an actual systemThere are several ways to tune the parameters of a PID controller. They involve the following procedures. For each, name the procedure and explain how the given measured information is used to pick the parameters of the PID controller.2.1.1: Example01 a. The controller is set to P only, and the system is operated in "closed-loop", meaning that the controller is connected and working. The gain is tuned up until a resonance is obtained. The amplitude and frequency of that resonance is measured.b. The system is kept in "open-loop" mode, and a step-function change is manually made to the system (through a disturbance or through the controller itself). The resulting response of the system is recorded as a function of time.Solutiona. We will use the Ziegler-Nichols method.Ki=0.5KuKu is the ultimate gain when the system started oscillating.b. We will use the Cohen-Coon method.We can locate the inflection point of the step function and draw a tangent. ?dead is located at the crossing of that tangent with t, and ? is located at the cross of the tangent with M(t)References* Svrcek, William Y., Mahoney, Donald P., Young, Brent R. A Real Time Approach to Process Control, 2nd Edition. John Wiley & Sons, Ltd.* Astrom, Karl J., Hagglund, Tore., Advanced PID Control, ISA, The Instrumentation, Systems and Automation Society.* "ACT Ziegler-Nichols Tuning," ourworld.compuserve.com/homepages/ACTGMBH/zn.htm* Ogata, Katsuhiko. System Dynamics, 4th Edition. Pearson Education, Inc.\3.1:      Additional Context - Standard PID Tuning Methods3.1.1: Cohen-Coon Method (Open-loop Test)      Step 1: Perform a step test to obtain the parameters of a FOPTD (first order plus time delay) model      Make sure the process is at an initial steady state      Introduce a step change in the manipulated variable      Wait until the process settles at a new steady state:      Step 2: Calculate process parameters: t1, Tau, Taudel, K, r as follows		t1 = t2 – (ln(2)) t3 / 1 – ln(2)		Tau = t3 - t1		Taudel = t1 – t0		K = B/A		      Step 3: Using the process parameters, use the prescribed values given byCohen and Coon.Table 1. Cohen-Coon Tuning Rules	KcTauintTauderP1/rK(1+r/3)PI1/rK(0.9+r/12)Taudel(30+3r/9+20r)PID1/rK(4/3+r/4)Taudel(32+6r/13+8r)Taudel(4/11+2r)3.2.1: Ziegler-Nichols Method (Closed-loop P-Control Test)        Step 1: Determine the sign of process gain (e.g. open loop test as in Cohen-Coon).        Step 2: Implement a proportional control and introducing a new set-point.        Step 3: Increase proportional gain until sustained periodic oscillation.        Step 4: Record ultimate gain and ultimate period: Ku and Pu.        Step 5: Evaluate control parameters as prescribed by Ziegler and NicholsTable 2. Ziegler Nichols Tuning RulesKcTauintTauderPKu/2PIKu/2.2Pu/1.2PIDKu/1.7Pu/2Pu/83.3.1: Tyreus-Luyben Method (Closed-loop P-Control test)        Step 1-4: Same as steps 1 to 4 of Ziegler-Nichols method above        Step 5: Evaluate control parameters as prescribed by Tyreus and Luyben        Table 2. Tyreus-Luyben Tuning Rules for PI and PID:KcTauintTauderPIKu/3.22.2PuPIDKu/2.22.2PuPu/6.33.4.1: Autotune Method (Closed-loop On-Off test)        Step 1: Let process settle to a steady state        Step 2: Move the setpoint to the current steady state        Step 3: Implement an on-off (relay) controller        If process gain is positive, u = {u0 + h if e >= 0 or u0 - h if e < 0}        If process gain is negative, u = {u0 - h if e >= 0 or u0 + h if e < 0}        Step 4: Let the process settle to a sustained periodic oscillation        Step 5: Evaluate ultimate gain using autotune formulas (can be obtain from the plots):        	Ku = 4/Pi *(h/a)        Step 6: Use either Ziegler-Nichols or Tyreus-Luyben prescribed tunings.4.1:      Additional Context - PID Tuning Methods        4.1.1: PID Control Introduction         The PID controller is the most common form of feedback. It was an essential element of early governors, and it became the standard tool when process control emerged in the 1940s. In process control today, more than 95% of the control loops are of PID type, most loops are actually PI control. PID controllers are today found in all areas where control is used. The controllers come in many different forms. There are stand-alone systems in boxes for one or a few loops, which are manufactured by the hundred thousand yearly. PID control is an important ingredient of a distributed control system. The controllers are also embedded in many special-purpose control systems. PID control is often combined with logic, sequential functions, selectors, and simple function blocks to build the complicated automation systems used for energy production, transportation, and manufacturing. Many sophisticated control strategies, such as model predictive control, are also organized hierarchically. PID control is used at the lowest level; the multivariable controller gives the setpoints to the controllers at the lower level. The PID controller can thus be said to be the “bread and butter of control engineering. It is an important’ component in every control engineer’s tool box. PID controllers have survived many changes in technology, from mechanics and pneumatics to microprocessors via electronic tubes, transistors, integrated circuits. The microprocessor has had a dramatic influence on the PID controller. Practically all PID controllers made today are based on microprocessors. This has given opportunities to provide additional features like automatic tuning, gain scheduling, and continuous adaptation.         4.2: The Algorithm         We will start by summarizing the key features of the PID controller. The “textbook” version of the PID algorithm is described by:        u(t) = K (e(t) + 1/Ti ∫_0^1??e(t)dt+Td(de(t)/dt)?        where:        y is the measured process variable,         r the reference variable,         u is the control signal        e is the control error (e = ysp ? y).                 The reference variable r is often called the set point. The control signal is thus a sum of three terms: the P-term (which is proportional to the error), the I-term (which is proportional to the integral of the error), and the D-term (which is proportional to the derivative of the error). The controller parameters are proportional gain K, integral time Ti, and derivative time Td. The integral, proportional and derivative part can be interpreted as control actions based on the past, the present and the future. The derivative part can also be interpreted as prediction by linear extrapolation.         Effects of Proportional, Integral and Derivative Action Proportional control is illustrated in Figure 6.1. The controller is given by (6.1) with Ti = ∞ and Td = 0. The figure shows that there is always a steady state error in proportional control. The error will decrease with increasing gain, but the tendency towards oscillation will also increase.         Figure 6.2 illustrates the effects of adding integral. It follows from (6.1) that the strength of integral action increases with decreasing integral time Ti. The figure shows that the steady state error disappears when integral action is used.         Figure 6.3 illustrates the effects of adding derivative action. Derivative actions ceases to be effective when Td is larger than a1s (one sixth of the period). Also notice that the period of oscillation increases when derivative time is increased.        There is much more to PID than is revealed by this brief overview. A faithful implementation of the equation will not result in a good controller. To obtain a good PID controller it is also necessary to consider:* Noise filtering and high frequency roll-off * Set point weighting and 2 DOF * Windup * Tuning * Computer implementation                                         In the case of the PID controller these issues emerged organically as the technology developed but they are actually important in the implementation of all controllers. Many of these questions are closely related to fundamental properties of feedback. Filtering        Differentiation is always sensitive to noise. This is clearly seen from the transfer function G(s) = s of a differentiator which goes to infinity for large s. The following example is also illuminating.                 Example 6.1: Differentiation amplifies high frequency noise:         Consider the signal y(t) = sin t + n(t) = sin t + an sin?nt         where the noise is sinusoidal noise with frequency ?. The derivative of the signal is dy(t)/dt = cos t + n(t) = cos t + an? cos?nt         The signal to noise ratio for the original signal is 1/an but the signal to noise ratio of the differentiated signal is ?/an. This ratio can be arbitrarily high if ? is large. In a practical controller with derivative action, it is therefore necessary to limit the high frequency gain of the derivative term.         This can be done by implementing the derivative term as D = ? (sKTd /1 + sTd/N) Y         instead of D = sTdY. The approximation given by (6.2) can be interpreted as the ideal derivative sTd filtered by a first-order system with the time constant Td/N. The approximation acts as a derivative for low-frequency signal components. The gain, however, is limited to K N. This means that high-frequency measurement noise is amplified at most by factor K N. Typical values of N are 8 to 20.	Further limitation of the high-frequency gain:        The transfer function from measurement y to controller output u of a PID controller with the approximate derivative is C(s)= ?K (1 + (1 /sTi) + (sTd/1 + sTd/N))        This controller has constant gain         ?lim?(s?∞)  C(s)= ???-K(1+N)?        		at high frequencies. It follows from the discussion on robustness against process variations that it is highly desirable to roll-off the controller gain at high frequencies. This can be achieved by additional low pass filtering of the control signal by:        F(s) = (1/(1+sTf)n        	where Tf is the filter time constant, and n is the order of the filter. The choice of Tf is a compromise between filtering capacity and performance. The value of Tf can be coupled to the controller time constants in the same way as for the derivative filter above. If the derivative time is used, Tf = Td/N is a suitable choice. If the controller is only PI, Tf = Ti/N may be suitable.         The controller can also be implemented as:         C(s)=?K (1 + 1/sTi + sTd) 1/(1 + sTd/N)2         This structure has the advantage that we can develop the design methods for an ideal PID controller and use an iterative design procedure. The controller is first designed for the process P(s). The design gives the controller parameter Td. An ideal controller for the process P(s)/(1+sTd/N)2 is then designed giving a new value of Td etc. Such a procedure will also give a clear picture of the trade-off between performance and filtering.Set Point Weighting:        When using the control law given by (6.1) it follows that a step change in the reference signal will result in an impulse in the control signal. This is often highly undesirable therefor derivative action is frequently not applied to the reference signal. This problem can be avoided by filtering the reference value before feeding it to the controller. Another possibility is to let proportional action act only on part of the reference signal. This is called set point weighting. A PID controller given by (6.1) then becomes:        u(t) = K (br(t) ? y(t) + 1/Ti ∫_0^t??e(tau)dr+Td (e(dr(t)/dt)-(dy(t)/dt))?         where b and c are additional parameter. The integral term must be based on error feedback to ensure the desired steady state. The controller given by equation above has a structure with two degrees of freedom because the signal path from y to u is different from that from r to u. The transfer function from r to u is:        U(s)/R(s) = Cr(s) = K(b+(1/sTi) + csTd)        And the transfer function from y to u is:        	U(s)/Y(s) = Cy(s) = K((1+1/sTi)+sTd)        Set point weighting is thus a special case of controllers having two degrees of freedom. The system obtained with the controller (6.4) respond to load disturbances and measurement noise in the same way as the controller (6.1) . The response to reference values can be modified by the parameters b and c. This is illustrated in Figure 6.4, which shows the response of a PID controller to setpoint changes, load disturbances, and measurement errors for different values of b. The figure shows clearly the effect of changing b. The overshoot for setpoint changes is smallest for b = 0, which is the case where the reference is only introduced in the integral term, and increases with increasing b. The parameter c is normally zero to avoid large transients in the control signal due to sudden changes in the setpoint.Different Parameterizations:         The PID algorithm given by Equation (6.1) can be represented by the transfer function:        	G(s) = K(1+(1/sTi)+sTd)    #(equation 6.7)        	A slightly different version is most common in commercial controllers. This controller is described by        		G’(s) = K’(1+(1/sT’i)) (1+sT’d) = K’(1+(T’d/T’i)+(1/sT’i)+sT’d)   #(equation 6.8)        		        		The controller given by Equation (6.7) is called non-interacting, and the one given by Equation (6.8) interacting. The interacting controller Equation (6.8) can always be represented as a non-interacting controller whose coefficients are given by:        K = K’((T’i+T’d/T’i)        Ti = T’i + T’d     #(equation 6.9)	        Td = (T’i*T’d/T’i+T’d)An interacting controller of the form Equation (6.8) that corresponds to a non-interacting controller can be found only if:	Ti>=4Td	The parameters are then given by:		K’ = K/2(1+SQR (1 ? 4Td/Ti)		T’i = Ti/2(1+SQR (1 ? 4Td/Ti)      #(Equation 6.10)		T’d = Ti/2(1+SQR (1 ? 4Td/Ti)The non-interacting controller given by Equation (6.7) is more general, and we will use that in the future. It is, however, sometimes claimed that the interacting controller is easier to tune manually. It is important to keep in mind that different controllers may have different structures when working with PID controllers. If a controller is replaced by another type of controller, the controller parameters may have to be changed. The interacting and the non-interacting forms differ only when both the I and the D parts of the controller are used. If we only use the controller as a P, PI, or PD controller, the two forms are equivalent. Yet another representation of the PID algorithm is given by:	G”(s) = k + (ki/s) + skd.        #(Equation 6.11)	The parameters are related to the parameters of standard form through:        k = K,         ki = K/Ti,        kd = KTd.	The representation Equation (6.11) is equivalent to the standard form, but the parameter values are quite different. This may cause great difficulties for anyone who is not aware of the differences, particularly if parameter 1/ki is called integral time and kd derivative time. It is even more confusing if ki is called integration time. The form given by Equation (6.11) is often useful in analytical calculations because the parameters appear linearly. The representation also has the advantage that it is possible to obtain pure proportional, integral, or derivative action by finite values of the parameters.The PIPD Controller:        The controller with set point weighting can also be represented by the block diagram in Figure 6.5. To see this we introduce the transfer functions of the blocks:        	Gpi(s) = k’ + k’1/s        Gpd(s) = 1 + k’d * s        Notice that the proportional gain of the PD controller must be one in order to have zero steady state error. The input-output relation of the complete controller is:        	U(s) = k’R(s) + k’i/s (R(s) ? Y(s)) ? (k’+ k’dh’i)Y(s) – k’k’dsY(s)        	Which shows that the controller is thus identical to the controller given        	        		by the figure above. The parameters are related in the following way:			k = k’ + k’dk’i        ki = k’i.        kd = k’k’d         Ti = k’+k’dk’i/k’i = k’/k’i         Td = k’k’d /k’i         b = k’/k’+k’dh’i         c = 0		Following the same pattern the controller with b = 0 and c = 0 is sometimes called an I-PD controller, and the controller with b = 1 and c = 0 is called a PI-D controller. Notice, however, that the representation given by (6.4) is much better suitable for tuning, because the parameters k, Ti and Td can first be determined to deal with load disturbances, measurement noise and process uncertainty. When this is done the response to set points can be adjusted by choosing the parameters b and c. The controller parameters appear in a much more complicated way in the PIPD controller.Windup:        Although many aspects of a control system can be understood based on linear theory, some nonlinear effects must be accounted for in practically all controllers. Windup is such a phenomenon, which is caused by the interaction of integral action and saturations. All actuators have limitations: a motor has limited speed, a valve cannot be more than fully opened or fully closed, etc. For a control system with a wide range of operating conditions, it may happen that the control variable reaches the actuator limits. When this happens the feedback loop is broken, and the system runs as an open loop because the actuator will remain at its limit independently of the process output. If a controller with integrating action is used, the error will continue to be integrated. This means that the integral term may become very large or, colloquially, it “winds up”. It is then required that the error has opposite sign for a long period before things return to normal. The consequence is that any controller with integral action may give large transients when the actuator saturates.         We will illustrate this by an example: Illustration of Integral windup        	The wind-up phenomenon is illustrated in the figure below, which shows control of an integrating process with a PI controller. The initial setpoint change is so large that the actuator saturates at the high limit. The integral term increases initially because the error is positive; it reaches its largest value at time t = 10 when the error goes through zero. The output remains saturated at this point because of the large value of the integral term. It does not leave the saturation limit until the error has been negative for a sufficiently long time to let the integral part come down to a small level. Notice that the control signal bounces between its limits several times. The net effect is a large overshoot and a damped oscillation where the control signal flips from one extreme to the other as in relay oscillation. The output finally comes so close to the setpoint that the actuator does not saturate. The system then behaves linearly and settles. The example show integrator windup which is generated by a change in the reference value. Windup may also be caused by large disturbances or equipment malfunctions. It can also occur in many other situations. The phenomenon of windup was well known to manufacturers of analog controllers who invented several tricks to avoid it. They were described under labels like preloading, batch unit, etc. Although the problem was well understood, there were often restrictions caused by the analog technology. The ideas were often kept as trade secrets and not much spoken about. The problem of windup was rediscovered when controllers were implemented digitally and several methods to avoid windup were presented in the literature. In the following section we describe some of the methods used to avoid windup.        			Setpoint Limitation:         One attempt to avoid integrator windup is to introduce limiters on the setpoint variations so that the controller output never reaches the actuator limits. This frequently leads to conservative bounds and poor performance. Furthermore, it does not avoid windup caused by disturbances.         Incremental Algorithms:        In the early phases of feedback control, integral action was integrated with the actuator by having a motor drive the valve directly. In this case windup is handled automatically because integration stops when the valve stops. When controllers were implemented by analog techniques, and later with computers, many manufacturers used a configuration that was an analog of the old mechanical design. This led to the so-called velocity algorithms. A velocity algorithm first computes the rate of change of the control signal which is then fed to an integrator. In some cases this integrator is a motor directly connected to the actuator. In other cases, the integrator is implemented internally in the controller. With this approach it is easy to avoid windup by inhibiting integration whenever the output saturates. This method is equivalent to back-calculation, which is described below. If the actuator output is not measured, a model that computes the saturated output can be used. It is also easy to limit the rate of change of the control signal.        Back-Calculation and Tracking:        Back-calculation works as follows: When the output saturates, the integral term in the controller is recomputed so that its new value gives an output at the saturation limit. It is advantageous not to reset the integrator instantaneously but dynamically with a time constant Tt. Figure 6.7 shows a block diagram of a PID controller with anti-windup based on back-calculation. The system has an extra feedback path that is generated by measuring the actual actuator output and forming an error signal (es) as the difference between the output of the controller (v) and the actuator output (u). Signal es is fed to the input of the integrator through gain 1/Tt. The signal is zero when there is no saturation. Thus, it will not have any effect on the normal operation when the actuator does not saturate. When the actuator saturates, the signal es is different from zero. The normal feedback path around the process is broken because the process input remains constant. There is, however, a feedback path around the integrator. Because of this, the integrator output is driven towards a value such that the integrator input becomes zero.                         The integrator input is:         (1/Tt) es + K/(Ti) e        Where:        e is the control error. Hence:        es = ? (KTt /Ti) e         in steady state. Since es = u ? v, it follows that:        	v = ulim + (K Tt/Ti) e        	where:        ulim is the saturating value of the control variable. This means that the signal v settles on a value slightly outside the saturation limit and the control signal can react as soon as the error changes time. This prevents the integrator from winding up. The rate at which the controller output is reset is governed by the feedback gain, 1/Tt, where Tt can be interpreted as the time constant, which determines how quickly the integral is reset. We call this the tracking time constant. It frequently happens that the actuator output cannot be measured. The anti-windup scheme just described can be used by incorporating a mathematical model of the saturating actuator, as is illustrated in Figure 6.7 - above.		Figure 6.8 shows what happens when a controller with anti-windup is applied to the system simulated in Figure 6.6. Notice that the output of the integrator is quickly reset to a value such that the controller output is at the saturation limit, and the integral has a negative value during the initial phase when the actuator is saturated. This behavior is drastically different from that in Figure 6.6, where the integral has a positive value during the initial transient. Also notice the drastic improvement in performance compared to the ordinary PI controller used in Figure 6.6. The effect of changing the values of the tracking time constant is illustrated in Figure 6.9. From this figure, it may thus seem advantageous to always choose a very small value of the time constant because the integrator is then reset quickly. However, some care must be exercised when introducing anti-windup in systems with derivative action. If the time constant is chosen too small, spurious errors can cause saturation of the output, which accidentally resets the integrator. The tracking time constant Tt should be larger than Td and smaller than Ti. A rule of thumb that has been suggested is to choose Tt = √TiTd.		        	Controllers with a Tracking Mode:        A controller with back-calculation can be interpreted as having two modes: the normal control mode, when it operates like an ordinary controller, and a tracking mode, when the controller is tracking so that it matches given inputs and outputs. Since a controller with tracking can operate in two modes, we may expect that it is necessary to have a logical signal for mode switching. However, this is not necessary, because tracking is automatically inhibited when the tracking signal w is equal to the controller output. This can be used with great advantage when building up complex systems with selectors and cascade control. Figure 6.10 shows a PID module with a tracking signal. The module has three inputs: the setpoint, the measured output, and a tracking signal. The new input TR is called a tracking signal because the controller output will follow this signal. Notice that tracking is inhibited when w = v. Using the module the system shown in Figure 6.7 can be presented as shown in Figure 6.11.Tuning:        All general methods for control design can be applied to PID control. A number of special methods that are tailor-made for PID control have also been developed, these methods are often called tuning methods. Irrespective of the method used it is essential to always consider the key elements of control, load disturbances, sensor noise, process uncertainty and reference signals. The most well known tuning methods are those developed by Ziegler and Nichols. They have had a major influence on the practice of PID control for more than half a century. The methods are based on characterization of process dynamics by a few parameters and simple equations for the controller parameters. It is surprising that the methods are so widely referenced because they give moderately good tuning only in restricted situations. Plausible explanations may be the simplicity of the methods and the fact that they can be used for simple student exercises in basic control courses.The Step Response Method:        One tuning method presented by Ziegler and Nichols is based on a process information in the form of the open-loop step response obtained from a bump test. This method can be viewed as a traditional method based on modeling and control where a very simple process model is used. The step response is characterized by only two parameters a and L, as shown in Figure 6.12. The point where the slope of the step response has its maximum is first determined, and the tangent at this point is drawn. The intersections between the tangent and the coordinate axes give the parameters a and L. The controller parameters are then obtained from Table 6.1. An estimate of the period Tp of the closed-loop system is also given in the table.                                                The Frequency Response Method: Ziegler and Nichols        A second method developed by Ziegler and Nichols is based on a simple characterization of the frequency response of the process dynamics. The design is based on knowledge of only one point on the Nyquist curve of the process transfer function P(s), namely the point where the Nyquist curve intersects the negative real axis. This point can be characterized by two parameters the frequency ?180 and the gain at that frequency k180 = |P(i?180)|. For historical reasons the point has been called the ultimate point and characterized by the parameters Ku = 1/K180 and Tu = 2π /?180, which are called the ultimate gain and the ultimate period. These parameters can be determined in the following way. Connect a controller to the process, set the parameters so that control action is proportional, i.e., Ti = ∞ and Td = 0. Increase the gain slowly until the process starts to oscillate. The gain when this occurs is Ku and the period of the oscillation is Tu. The parameters of the controller are then given by Table 6.2. An estimate of the period Tp of the dominant dynamics of the closed-loop system is also given in the table. The frequency response method can be viewed as an empirical tuning procedure where the controller parameters are obtained by direct experiments on the process combined with some simple rules. For a proportional controller the rule is simply to increase the gain until the process oscillates and then reduce it by 50%.        Assessment of the Ziegler Nichols Methods:        The Ziegler-Nichols tuning rules were developed to give closed loop systems with good attenuation of load disturbances. The methods were based on extensive simulations. The design criterion was quarter amplitude decay ratio, which means that the amplitude of an oscillation should be reduced by a factor of four over a whole period. This corresponds to closed loop poles with a relative damping of about ? = 0.2, which is too small. Controllers designed by the Ziegler-Nichols rules thus inherently give closed loop systems with poor robustness. It also turns out that it is not sufficient to characterize process dynamics by two parameters only. The methods developed by Ziegler and Nichols have been been very popular in spite of these drawbacks. Practically all manufacturers of controller have used the rules with some modifications in recommendations for controller tuning. One reason for the popularity of the rules is that they are simple and easy to explain. The tuning rules give ball park figures. Final tuning is then done by trial and error. Another (bad) reason is that the rules lend themselves very well to simple exercises for control education. With the insight into controller design that has developed over the years it is possible to develop improved tuning rules that are almost as simple as the Zigler-Nichols rules. These rules are developed by starting with a solid design method that gives robust controllers with effective disturbance attenuation. We illustrate with some rules where the process is characterized by three parameters.        An Improved Step Response Method:        This method characterizes the unit step response by three parameters K, L and T for stable processes and Kv = K/T and L for integrating processes. This parameterization matches the transfer functions:        P1(s) = (kp/(1 + sT)) e?sL.        P2(s) = (kv/s) e?sL         The transfer function P1(s), which is called a first order system with time delay or a K LT model. Parameter L is determined from the intercept of the tangent with largest slope with the time axis as was described in Figure 6.12. Parameter T is also determined as shown in the figure as the difference between the time when the step response reaches 63% of its steady state value. Parameter kp is the static gain of the system. The parameter kv is the largest slope of the unit step response. Parameter L is called the apparent time delay and parameter T the apparent time constant or the apparent lag. The adverb apparent is added to indicate that parameters are based on approximations. The parameter ? = L/(L + T) = tau, is called the relative time delay. This parameter is a good indicator of process dynamics. To obtain improved tuning rules we use a design method that maximizes integral gain subject to the robustness constraint that the maximum sensitivity is less than Ms = 1.4. The procedure has been applied to a a large test batch representing many different processes. One tuning rule is:        K = {0.3(T/KvL) for + L < 2T and/or 0.15Kp for 2T < L}        Ti = {8L for L < 0.1T #(Equation 6.12) and/or 0.8T for 0.1T < L < 2T and/or 0.4L for 2T < L}        The properties of the improved tuning rules are illustrated by applying them to systems with the transfer functions:        	P1(s) = 1/(s + 1)(0.2s + 1)        P2(s) = 1/(s + 1)4        P3(s) = (1/(0.05s + 1)2) e?1.2s		The process P1(s) has lag dominated dynamics, process P3(s) has delay dominated dynamics and process P2(s) has balanced dynamics. Figure 6.14 shows the response to a step change in the reference at time zero and a step change in a load disturbance at the process input for PI control of the process P1(s). The dashed lines show the responses obtained by the Ziegler-Nichols step response method and the full line shows the response obtained with the improved rule which restricted the maximum sensitivity to 1.4. The oscillatory responses to obtained by the Ziegler-Nichols method are clearly visible in the figure which reflects the design choice of quarter amplitude damping. The response to load disturbances obtained by the Ziegler-Nichols method comes at a price of poor sensitivity. There is also a very large overshoot in the response to reference values. Figure 6.15 shows the corresponding responses for the system P4(s). The oscillatory character obtained with Ziegler Nichols tuning is clearly visible. Figure 6.16 shows the response for a process that is delay dominated. The figure shows that Ziegler-Nichols tuning performs very poorly for this process. Overall, we find that the improved tuning rules work for a wide range of processes and that they give robust systems with good responses.	         	Computer Implementation:        Most controllers are nowadays implemented in computers. In this section we will discuss many practical issues related to computer implementation. Sampling When the controller is implemented in a computer, the analog inputs are read, and the outputs are set with a certain sampling period. This is a drawback compared to the analog implementations, since the sampling introduces dead-time in the control loop. When a digital computer is used to implement a control law, the ideal sequence of operation is the following:        1. Wait for clock interrupt        2. Read analog input        3. Compute control signal        4. Set analog output        5. Update controller variables        6. Go to 1                With this implementation, the delay is minimized. If the analog input is read with a sampling period h, the average delay of the measurement signal is h/2. The computation time is often short compared to the sampling period. This means that the total delay is about h/2. However, most controllers and instrument systems do not organize the calculation in this way. Therefore, the delays introduced because of the sampling is often several sampling periods.                Aliasing:        The sampling mechanism introduces some unexpected phenomena, which must be taken into account in a good digital implementation of a PID controller. To explain these, consider the signalsL:        s(t) = cos(n?2s t ± ?t)         and        sa(t) = cos(?t)        where:	        ? s = 2π /h [rad/s] is the sampling frequency. Well-known formulas for the cosine function imply that the values of the signals at the sampling instants [kh, k = 0, 1, 2, ...] have the property:        s(kh) = cos(nkh? s ± ?kh) = cos(?kh) = sa(?kh)		The signals s and sa thus have the same values at the sampling instants. This means that there is no way to separate the signals if only their values at the sampling instants are known. Signal sa is, therefore, called an alias of signal s. This is illustrated in Figure 6.17. A consequence of the aliasing effect is that a high-frequency disturbance after sampling may appear as a low-frequency signal. In Figure 6.17 the sampling period is 1s and the sinusoidal disturbance has a period of 6/5 s. After sampling, the disturbance appear as a sinusoid with the frequency:        fa = 1 – 5/6 = 1/6 Hz         This low-frequency signal with time period 6 s is seen in the figure.        	Prefiltering:        The aliasing effect can create significant difficulties if proper precautions are not taken. High frequencies, which in analog controllers normally are effectively eliminated by low-pass filtering, may, because of aliasing, appear as low-frequency signals in the bandwidth of the sampled control system. To avoid these difficulties, an analog prefilter (which effectively eliminates all signal components with frequencies above half the sampling frequency) should be introduced. Such a filter is called an anti-aliasing filter. A second-order Butterworth filter is a common anti-aliasing filter. Higher-order filters are also used in critical applications. The selection of the filter bandwidth is illustrated by the following example.                Example 6.3—Selection of prefilter bandwideth:        Assume it is desired that the prefilter attenuate signals by a factor of 16 at half the sampling frequency. If the filter bandwidth is ? b and the sampling frequency is ? s, we get:        (? s/2? b)2 = 16        Hence,        ?b = (1/8)?s         Notice that the dynamics of the prefilter is often significant. It should be accounted for in the control design by combining it with the process dynamics.Discretization:        To implement a continuous-time control law, such as a PID controller in a digital computer, it is necessary to approximate the derivatives and the integral that appear in the control law. A few different ways to do this are presented below:         Proportional Action - The proportional term is:        P = K(bysp ? y)        This term is implemented simply by replacing the continuous variables with their sampled versions. Hence,        P(tk) = K (bysp(tk) ? y(tk))   #(Equation 6.13)        where {tk} denotes the sampling instants, i.e., the times when the computer reads the analog input.	Integral Action - The integral term is given by:        I(t) = K/Ti ∫_0^t??e(s)ds ?        It follows that,        dI/dt = (K/Ti) e    #(Equation 6.14)	The derivative is approximated by a forward difference gives:        I(tk+1) ? I(tk)/h = (K/Ti) e(tk)        This leads to the following recursive equation for the integral term:        I(tk+1) = I(tk) + (Kh/Ti) e(tk)    #(Equation 6.15)	Derivative Action - The derivative term is given by:  Equation (6.2), i.e.         Td/N (dD/dt) + D = ?KTd (dy/dt)     #(Equation 6.16)        This equation can be approximated in the same way as the integral term. In this case we approximate the derivatives by a backward difference:        (Td/N)(D(tk) ? D(tk?1)/h) + D(tk) = ?KTd (y(tk) ? y(tk?1)/h                This can be rewritten as:        D(tk) = (Td/(Td + Nh)) D(tk?1) – (KTdN/Td+Nh) (y(tk) ? y(tk?1))     #(Equation 6.17)		The advantage by using a backward difference is that the parameter Td/(Td+Nh) is in the range of 0 to 1 for all values of the parameters. This guarantees that the difference equation is stable.         Summarizing we find that the PID controller can be approximated by:        p(tk) = k ? (br(tk) ? y(tk))        e(tk) = r(tk) ? y(tk)        d(tk) = (Td/( Td + Nh))(d(tk?1) ? kN (y(tk) ? y(tk?1)))        u(tk) = p(tk) + i(tk) + d(tk)        i(tk+1) = i(tk) + (kh/Ti) e(tk)Velocity Algorithms - Method used with Studio5000 PIDE:         The algorithms described so far are called positional algorithms because the output of the algorithms is the control variable. In certain cases the control system is arranged in such a way that the control signal is driven directly by an integrator, e.g., a motor. It is then natural to arrange the algorithm in such a way that it gives the velocity of the control variable. The control variable is then obtained by integrating its velocity. An algorithm of this type is called a velocity algorithm. A block diagram of a velocity algorithm for a PID controller is shown in Figure 6.18. Velocity algorithms were commonly used in many early controllers that were built around motors. In several cases, the structure was retained by the manufacturers when technology was changed in order to maintain functional compatibility with older equipment. Another reason is that many practical issues, like wind-up protection and bumpless parameter changes, are easy to implement using the velocity algorithm. This is discussed further in Sections 6.5 and 6.7. In digital implementations velocity algorithms are also called incremental algorithms. Incremental algorithm - The incremental form of the PID algorithm is obtained by computing the time differences of the controller output and adding the increments:        ∆u(tk) = u(tk) ? u(tk?1) = ∆P(tk) + ∆I(tk) + ∆D(tk)        	In some cases, integration is performed externally. This is natural when a stepper motor is used. The output of the controller should then represent the increments of the control signal, and the motor implements the integrator. The increments of the proportional part, the integral part, and the derivative part are easily calculated from Equations 6.13, 6.15 and 6.17: 	∆P(tk) = P(tk) ? P(tk ?1) = K (bysp(tk) ? y(tk) ? bysp(tk ?1) + y(tk ?1))       ∆I(tk) = I(tk) ? I(tk ?1) = bi1 e(tk) + bi2 e(tk ?1)       ∆D(tk) = D(tk) ? D(tk ?1) = ad∆D(tk ?1) ? bd (y(tk) ? 2y(tk ?1) + y(tk ?2))       One advantage with the incremental algorithm is that most of the computations are done using increments only. Short word-length calculations can often be used. It is only in the final stage where the increments are added that precision is needed.Velocity algorithms for controllers without integral action:       A velocity algorithm cannot be used directly for a controller without integral action, because such a controller cannot keep the stationary value. This can be understood from the block diagram in Figure 6.19A, which shows a proportional controller in velocity form. Stationarity can be obtained for any value of the control error e, since the output from the derivation block is zero for any constant input. The problem can be avoided with the modification shown in Figure 6.19B. Here, stationarity is only obtained when u = K e + ub. If a sampled PID controller is used, a simple version of the method illustrated in figure 6.19B is obtained by implementing the P controller as:       ∆u(t) = u(t) ? u(t ? h) = K e(t) + ub ? u(t ? h)       Where,       h is the sampling period.	Feedforward control:	In feedforward control, the control signal is composed of two terms, 		u = uFB + uFF 	Here uFB is the feedback component and uFF is the feedforward component, either from a measurable disturbance or from the setpoint. To avoid integrator windup, it is important that the anti-windup mechanism acts on the final control signal u, and not only on the feedback component uFB . Unfortunately, many of the block-oriented instrument systems available today have the anti-windup mechanisms inside the feedback controller blocks, without any possibility to add feedforward signals to these blocks. Hence, the feedforward signals must be added after the controller blocks. This may lead to windup. Because of this, several tricks, like feeding the feedforward signal through high-pass filters, are used to reduces the windup problem. These strategies do, however, lead to a less effective feedforward. Incremental algorithms are efficient for feedforward implementation. By first adding the increments of the feedback and feedforward components,		∆u = ∆uFB + ∆uFF	and then forming the control signal as:		u(t) = u(t ? h) + ∆u(t)windup is avoided. This requires that the feedback control blocks have inputs for feedforward signals.Operational Aspects:	Practically all controllers can be run in two modes: manual or automatic. In manual mode the controller output is manipulated directly by the operator, typically by pushing buttons that increase or decrease the controller output. A controller may also operate in combination with other controllers, such as in a cascade or ratio connection, or with nonlinear elements, such as multipliers and selectors. This gives rise to more operational modes. The controllers also have parameters that can be adjusted in operation. When there are changes of modes and parameters, it is essential to avoid switching transients. The way the mode switchings and the parameter changes are made depends on the structure chosen for the controller. Bumpless Transfer Between Manual and Automatic:	Since the controller is a dynamic system, it is necessary to make sure that the state of the system is correct when switching the controller between manual and automatic mode. When the system is in manual mode, the control algorithm produces a control signal that may be different from the manually generated control signal. It is necessary to make sure that the two outputs coincide at the time of switching. This is called bumpless transfer. Bumpless transfer is easy to obtain for a controller in incremental form. This is shown in Figure 6.20. The integrator is provided with a switch so that the signals are either chosen from the manual or the automatic increments. Since the switching only influences the increments there will not be any large transients. A similar mechanism can be used in the series, or interacting, implementation of a PID controller shown in Figure 6.22. In this case there will be a switching transient if the output of the PD part is not zero at the switching instant.			For controllers with parallel implementation, the integrator of the PID controller can be used to add up the changes in manual mode. The controller shown in Figure 6.22 is such a system. This system gives a smooth transition between manual and automatic mode provided that the switch is made when the output of the PD block is zero. If this is not the case, there will be a switching transient. It is also possible to use a separate integrator to add the incremental changes from the manual control device. To avoid switching transients in such a system, it is necessary to make sure that the integrator in the PID controller is reset to a proper value when the controller is in manual mode. Similarly, the integrator associated with manual control must be reset to a proper value when the controller is in automatic mode. This can be realized with the circuit shown in Figure 6.23. With this system the switch between manual and automatic is smooth even if the control error or its derivative is different from zero at the switching instant. When the controller operates in manual mode, as is shown in Figure 6.23, the feedback from the output v of the PID controller tracks the output u. With efficient tracking the signal v will thus be close to u at all times. There is a similar tracking mechanism that ensures that the integrator in the manual control circuit tracks the controller output.Bumpless Parameter Changes:A controller is a dynamical system. A change of the parameters of a dynamical system will naturally result in changes of its output. Changes in the output can be avoided, in some cases, by a simultaneous change of the state of the system. The changes in the output will also depend on the chosen realization. With a PID controller it is natural to require that there be no drastic changes in the output if the parameters are changed when the error is zero. This will hold for all incremental algorithms because the output of an incremental algorithm is zero when the input is zero, irrespective of the parameter values. For a position algorithm it depends, however, on the implementation.        Assume that the state is chosen as:       xI = ∫^t?e(?)d ?       when implementing the algorithm. The integral term is then:       I = (K/Ti) xI        Any change of K or Ti will then result in a change of I. To avoid bumps when the parameters are changed, it is essential that the state be chosen as:       xI = ∫^t??(K(?)/Ti(?)?)e(?)dt       when implementing the integral term.        With sensible precautions, it is easy to ensure bumpless parameter changes if parameters are changed when the error is zero. There is, however, one case where special precautions have to be taken, namely, if setpoint weighting is used. To have bumpless parameter changes in such a case it is necessary that the quantity P + I is invariant to parameter changes. This means that when parameters are changed, the state I should be changed as follows:       Inew = Iold + Kold(bold ysp ? y) ? Knew(bnew ysp ? y)       To build automation systems it is useful to have suitable modules. Figure 6.24 shows the block diagram for a manual control module. It has two inputs, a tracking input and an input for the manual control commands. The system has two parameters, the time constant Tm for the manual control input and the reset time constant Tt. In digital implementations it is convenient to add a feature so that the command signal accelerates as long as one of the increase-decrease buttons are pushed. Using the module for PID control and the manual control module in Figure 6.24, it is straightforward to construct a complete controller. Figure 6.25 shows a PID controller with internal or external setpoints via increase/decrease buttons and manual automatic mode. Notice that the system only has two switches.              	Computer Code:As an illustration, the following is a computer code for a PID algorithm. The controller handles both anti-windup and bumpless transfer. 	"Compute controller coefficients	bi=K*h/Ti 	"integral gain	ad=(2*Td-N*h)/(2*Td+N*h)	bd=2*K*N*Td/(2*Td+N*h) 	"derivative gain	a0=h/Tt 	"Bumpless parameter changes	I=I+Kold*(bold*ysp-y)-Knew*(bnew*ysp-y) 	"Control algorithm	r=adin(ch1) 	"read setpoint from ch1	y=adin(ch2) 	"read process variable from ch2	P=K*(b*ysp-y) 	"compute proportional part	D=ad*D-bd*(y-yold) 	"update derivative part	v=P+I+D 	"compute temporary output	u=sat(v,ulow,uhigh) 	"simulate actuator saturation	daout(ch1) 	"set analog output ch1	I=I+bi*(ysp-y)+ao*(u-v) 	"update integral 	yold=y 	"update old process output	The computation of the coefficients should be done only when the controller parameters are changed. Precomputation of the coefficients ad, ao, bd, and bi saves computer time in the main loop. The main program must be called once every sampling period. The program has three states: yold, I, and D. One state variable can be eliminated at the cost of a less readable code. Notice that the code includes derivation of the process output only, proportional action on part of the error only (b != 1), and anti-windup.Summary In this Section we have given a detailed treatment of the PID controller, which is the most common way controller. A number of practical issues have been discussed. Simple controllers like the PI and PID controller are naturally not suitable for all processes. The PID controller is suitable for processes with almost monotone step responses provided that the requirements are not too stringent. The quantity:	m = ∫_0^t?g(t)dt/(∫_0^t?|g(t)|dt)	where g(t) is the impulse response can be used as a measure of monotonicity. PID control is not suitable for processes that are highly oscillatory or when the requirements are extreme. The PI controller has no phase advance. This means that the PI controller will not work for systems which have phase lag of 180? or more. The double integrator is a typical example. Controller with derivative action can provide phase advance up to about 50?. Simple processes can be characterized by the relative time delay ? introduced in the Ziegler Nichols tuning procedure. PI control is often satisfactory for processes that are lag dominated, i.e. when ? close to one. Derivative action is typically beneficial for processes with small relative delay ?.<END OF DOCUMENNT>Bottom of Form
