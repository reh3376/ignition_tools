#!/usr/bin/env python3
"""
Phase 12.7: API Server Implementation
Following crawl_mcp.py methodology with comprehensive validation and testing.

This module implements a production-ready FastAPI server for the IGN Scripts
Code Intelligence System with systematic environment validation, comprehensive
testing, and progressive complexity deployment.
"""

import asyncio
import os
import sys
import time
from contextlib import asynccontextmanager
from pathlib import Path
from typing import Any, Dict, List, Optional
from datetime import datetime

import uvicorn
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, ValidationError

# Add project root to path for imports
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Load environment variables
load_dotenv()

# Import existing modules
try:
    from src.core.cli_core import LearningSystemCLI, main as cli_main
    from src.ignition.system.enhanced_wrappers import SystemWrapper
    CLI_AVAILABLE = True
except ImportError as e:
    print(f"Warning: CLI modules not available: {e}")
    LearningSystemCLI = None
    cli_main = None
    SystemWrapper = None
    CLI_AVAILABLE = False

# Global variables for server state
server_start_time = None
request_count = 0
error_count = 0


# ============================================================================
# 1. ENVIRONMENT VALIDATION FIRST (crawl_mcp.py methodology)
# ============================================================================

def validate_api_environment() -> Dict[str, Any]:
    """
    Validate environment setup before starting API server.
    Following crawl_mcp.py methodology: Environment validation first.
    """
    validation_results = {
        "valid": True,
        "checks": {},
        "errors": [],
        "warnings": []
    }
    
    # Check Python version
    python_version = sys.version_info
    if python_version >= (3, 8):
        validation_results["checks"]["python_version"] = "✅ PASS"
    else:
        validation_results["checks"]["python_version"] = "❌ FAIL"
        validation_results["errors"].append(f"Python 3.8+ required, found {python_version}")
        validation_results["valid"] = False
    
    # Check required environment variables
    required_env_vars = ["NEO4J_URI", "NEO4J_USER", "NEO4J_PASSWORD"]
    env_vars_present = []
    
    for var in required_env_vars:
        if os.getenv(var):
            env_vars_present.append(var)
        else:
            validation_results["warnings"].append(f"Environment variable {var} not set")
    
    if len(env_vars_present) >= 2:  # At least 2 out of 3 for basic functionality
        validation_results["checks"]["environment_variables"] = "✅ PASS"
    else:
        validation_results["checks"]["environment_variables"] = "⚠️ PARTIAL"
    
    # Check CLI availability
    if CLI_AVAILABLE:
        validation_results["checks"]["cli_modules"] = "✅ PASS"
    else:
        validation_results["checks"]["cli_modules"] = "⚠️ PARTIAL"
        validation_results["warnings"].append("CLI modules not fully available")
    
    # Check port availability (default 8000)
    import socket
    port = int(os.getenv("API_PORT", "8000"))
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind(("localhost", port))
        validation_results["checks"]["port_availability"] = "✅ PASS"
    except OSError:
        validation_results["checks"]["port_availability"] = "⚠️ PARTIAL"
        validation_results["warnings"].append(f"Port {port} may be in use")
    
    # Check project structure
    required_dirs = ["src", "docs", "tests"]
    missing_dirs = []
    
    for dir_name in required_dirs:
        if (project_root / dir_name).exists():
            continue
        else:
            missing_dirs.append(dir_name)
    
    if not missing_dirs:
        validation_results["checks"]["project_structure"] = "✅ PASS"
    else:
        validation_results["checks"]["project_structure"] = "⚠️ PARTIAL"
        validation_results["warnings"].extend([f"Missing directory: {d}" for d in missing_dirs])
    
    return validation_results


def format_api_error(error: Exception) -> str:
    """
    Format API errors for user-friendly messages.
    Following crawl_mcp.py error handling patterns.
    """
    error_str = str(error).lower()
    
    if "connection" in error_str or "refused" in error_str:
        return "Service connection failed. Check if dependencies are running."
    elif "authentication" in error_str or "unauthorized" in error_str:
        return "Authentication failed. Check credentials and permissions."
    elif "timeout" in error_str:
        return "Request timeout. Service may be overloaded or unavailable."
    elif "validation" in error_str:
        return "Input validation failed. Check request format and required fields."
    elif "not found" in error_str or "404" in error_str:
        return "Requested resource not found. Check endpoint URL and parameters."
    else:
        return f"API error: {error}"


# ============================================================================
# 2. COMPREHENSIVE INPUT VALIDATION (Pydantic models)
# ============================================================================

class HealthCheckResponse(BaseModel):
    """Health check response model."""
    status: str = Field(..., description="Service status")
    timestamp: datetime = Field(..., description="Response timestamp")
    uptime_seconds: float = Field(..., description="Server uptime in seconds")
    version: str = Field(..., description="API version")
    environment: str = Field(..., description="Environment name")


class CLICommandRequest(BaseModel):
    """CLI command execution request model."""
    command: str = Field(..., min_length=1, max_length=1000, description="CLI command to execute")
    args: Optional[List[str]] = Field(default=[], description="Command arguments")
    timeout: Optional[int] = Field(default=30, ge=1, le=300, description="Command timeout in seconds")


class CLICommandResponse(BaseModel):
    """CLI command execution response model."""
    success: bool = Field(..., description="Command execution success status")
    output: str = Field(..., description="Command output")
    error: Optional[str] = Field(default=None, description="Error message if failed")
    execution_time: float = Field(..., description="Execution time in seconds")
    command: str = Field(..., description="Executed command")


class SystemStatusResponse(BaseModel):
    """System status response model."""
    api_server: str = Field(..., description="API server status")
    cli_system: str = Field(..., description="CLI system status")
    database: str = Field(..., description="Database connectivity status")
    environment_validation: Dict[str, str] = Field(..., description="Environment validation results")
    metrics: Dict[str, Any] = Field(..., description="System metrics")


class ErrorResponse(BaseModel):
    """Standard error response model."""
    error: str = Field(..., description="Error message")
    details: Optional[str] = Field(default=None, description="Detailed error information")
    timestamp: datetime = Field(..., description="Error timestamp")
    request_id: Optional[str] = Field(default=None, description="Request identifier")


# ============================================================================
# 3. ROBUST ERROR HANDLING (try-catch with user-friendly messages)
# ============================================================================

class APIErrorHandler:
    """Centralized error handling following crawl_mcp.py patterns."""
    
    @staticmethod
    def handle_validation_error(error: ValidationError) -> JSONResponse:
        """Handle Pydantic validation errors."""
        error_details = []
        for err in error.errors():
            field = " -> ".join(str(loc) for loc in err["loc"])
            error_details.append(f"{field}: {err['msg']}")
        
        return JSONResponse(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            content={
                "error": "Validation failed",
                "details": "; ".join(error_details),
                "timestamp": datetime.now().isoformat()
            }
        )
    
    @staticmethod
    def handle_general_error(error: Exception, request_id: str = None) -> JSONResponse:
        """Handle general API errors with user-friendly messages."""
        global error_count
        error_count += 1
        
        formatted_error = format_api_error(error)
        debug_details = str(error) if os.getenv("DEBUG", "false") == "true" else ""
        
        return JSONResponse(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            content={
                "error": formatted_error,
                "details": debug_details if debug_details else None,
                "timestamp": datetime.now().isoformat(),
                "request_id": request_id or ""
            }
        )


# ============================================================================
# 4. MODULAR TESTING APPROACH (Progressive complexity testing)
# ============================================================================

class APIServerTester:
    """Comprehensive API server testing following crawl_mcp.py methodology."""
    
    def __init__(self):
        self.test_results = {
            "environment_validation": {},
            "server_initialization": {},
            "endpoint_functionality": {},
            "error_handling": {},
            "performance_metrics": {}
        }
    
    async def run_comprehensive_tests(self) -> Dict[str, Any]:
        """Run comprehensive API server tests."""
        print("🧪 Starting API Server Comprehensive Testing")
        print("Following crawl_mcp.py methodology: Progressive complexity testing")
        
        # Test 1: Environment validation
        await self._test_environment_validation()
        
        # Test 2: Server initialization
        await self._test_server_initialization()
        
        # Test 3: Endpoint functionality
        await self._test_endpoint_functionality()
        
        # Test 4: Error handling
        await self._test_error_handling()
        
        # Test 5: Performance metrics
        await self._test_performance_metrics()
        
        # Calculate overall success
        total_tests = sum(len(category) for category in self.test_results.values())
        passed_tests = sum(
            1 for category in self.test_results.values()
            for test_result in category.values()
            if test_result.get("status") == "PASS"
        )
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        print(f"✅ Testing completed: {passed_tests}/{total_tests} tests passed ({success_rate:.1f}%)")
        
        return {
            "overall_success": success_rate >= 80,
            "success_rate": success_rate,
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "test_results": self.test_results,
            "timestamp": datetime.now().isoformat()
        }
    
    async def _test_environment_validation(self):
        """Test environment validation."""
        try:
            validation_result = validate_api_environment()
            self.test_results["environment_validation"]["validation_check"] = {
                "status": "PASS" if validation_result["valid"] else "PARTIAL",
                "details": validation_result["checks"],
                "errors": validation_result["errors"],
                "warnings": validation_result["warnings"]
            }
        except Exception as e:
            self.test_results["environment_validation"]["validation_check"] = {
                "status": "FAIL",
                "error": str(e)
            }
    
    async def _test_server_initialization(self):
        """Test server initialization components."""
        # Test FastAPI app creation
        try:
            test_app = FastAPI(title="Test API")
            self.test_results["server_initialization"]["fastapi_creation"] = {
                "status": "PASS",
                "details": "FastAPI app created successfully"
            }
        except Exception as e:
            self.test_results["server_initialization"]["fastapi_creation"] = {
                "status": "FAIL",
                "error": str(e)
            }
        
        # Test CLI availability
        if CLI_AVAILABLE:
            self.test_results["server_initialization"]["cli_availability"] = {
                "status": "PASS",
                "details": "CLI modules available"
            }
        else:
            self.test_results["server_initialization"]["cli_availability"] = {
                "status": "PARTIAL",
                "details": "CLI modules not fully available"
            }
    
    async def _test_endpoint_functionality(self):
        """Test endpoint functionality."""
        # Test health check endpoint logic
        try:
            global server_start_time
            if server_start_time is None:
                server_start_time = time.time()
            
            uptime = time.time() - server_start_time
            health_response = HealthCheckResponse(
                status="healthy",
                timestamp=datetime.now(),
                uptime_seconds=uptime,
                version="12.7.0",
                environment=os.getenv("ENVIRONMENT", "development")
            )
            
            self.test_results["endpoint_functionality"]["health_check"] = {
                "status": "PASS",
                "details": f"Health check response created: {health_response.status}"
            }
        except Exception as e:
            self.test_results["endpoint_functionality"]["health_check"] = {
                "status": "FAIL",
                "error": str(e)
            }
        
        # Test CLI command validation
        try:
            test_request = CLICommandRequest(
                command="status",
                args=[],
                timeout=30
            )
            
            self.test_results["endpoint_functionality"]["cli_validation"] = {
                "status": "PASS",
                "details": f"CLI request validation successful: {test_request.command}"
            }
        except Exception as e:
            self.test_results["endpoint_functionality"]["cli_validation"] = {
                "status": "FAIL",
                "error": str(e)
            }
    
    async def _test_error_handling(self):
        """Test error handling mechanisms."""
        # Test validation error handling
        try:
            error_handler = APIErrorHandler()
            # Create a simple validation error for testing
            test_exception = ValueError("Test validation error")
            response = error_handler.handle_general_error(test_exception, "test-validation")
            
            self.test_results["error_handling"]["validation_errors"] = {
                "status": "PASS",
                "details": f"Validation error handled: {response.status_code}"
            }
        except Exception as e:
            self.test_results["error_handling"]["validation_errors"] = {
                "status": "FAIL",
                "error": str(e)
            }
        
        # Test general error handling
        try:
            error_handler = APIErrorHandler()
            test_exception = Exception("Test error")
            response = error_handler.handle_general_error(test_exception, "test-123")
            
            self.test_results["error_handling"]["general_errors"] = {
                "status": "PASS",
                "details": f"General error handled: {response.status_code}"
            }
        except Exception as e:
            self.test_results["error_handling"]["general_errors"] = {
                "status": "FAIL",
                "error": str(e)
            }
    
    async def _test_performance_metrics(self):
        """Test performance metrics collection."""
        try:
            global request_count, error_count
            request_count = 10
            error_count = 1
            
            metrics = {
                "total_requests": request_count,
                "total_errors": error_count,
                "error_rate": (error_count / request_count * 100) if request_count > 0 else 0,
                "uptime_seconds": time.time() - (server_start_time or time.time())
            }
            
            self.test_results["performance_metrics"]["metrics_collection"] = {
                "status": "PASS",
                "details": f"Metrics collected: {len(metrics)} metrics"
            }
        except Exception as e:
            self.test_results["performance_metrics"]["metrics_collection"] = {
                "status": "FAIL",
                "error": str(e)
            }


# ============================================================================
# 5. PROGRESSIVE COMPLEXITY (Basic → Standard → Advanced → Enterprise)
# ============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Application lifespan management with proper resource handling.
    Following crawl_mcp.py resource management patterns.
    """
    global server_start_time
    
    # Startup: Environment validation first
    print("🚀 Starting API Server with crawl_mcp.py methodology")
    print("Step 1: Environment validation")
    
    validation_result = validate_api_environment()
    if not validation_result["valid"]:
        print("❌ Environment validation failed:")
        for error in validation_result["errors"]:
            print(f"  - {error}")
        raise RuntimeError("Environment validation failed")
    
    print("✅ Environment validation passed")
    
    # Initialize server start time
    server_start_time = time.time()
    
    # Initialize CLI if available
    if CLI_AVAILABLE:
        print("✅ CLI modules available")
    else:
        print("⚠️ CLI modules not fully available")
    
    print("🎯 API Server ready for requests")
    
    yield
    
    # Shutdown: Clean up resources
    print("🔄 Shutting down API Server")
    print("✅ Cleanup completed")


# Create FastAPI application
app = FastAPI(
    title="IGN Scripts API Server",
    description="Production-ready API server for IGN Scripts Code Intelligence System",
    version="12.7.0",
    lifespan=lifespan
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================================================
# 6. API ENDPOINTS (Progressive complexity)
# ============================================================================

@app.get("/health", response_model=HealthCheckResponse)
async def health_check():
    """
    Health check endpoint.
    Basic level: Simple health status.
    """
    global server_start_time, request_count
    request_count += 1
    
    try:
        uptime = time.time() - (server_start_time or time.time())
        
        return HealthCheckResponse(
            status="healthy",
            timestamp=datetime.now(),
            uptime_seconds=uptime,
            version="12.7.0",
            environment=os.getenv("ENVIRONMENT", "development")
        )
    except Exception as e:
        global error_count
        error_count += 1
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=format_api_error(e)
        )


@app.get("/status", response_model=SystemStatusResponse)
async def system_status():
    """
    System status endpoint.
    Standard level: Comprehensive system status.
    """
    global request_count, error_count
    request_count += 1
    
    try:
        # Environment validation
        env_validation = validate_api_environment()
        
        # System metrics
        uptime = time.time() - (server_start_time or time.time())
        metrics = {
            "uptime_seconds": uptime,
            "total_requests": request_count,
            "total_errors": error_count,
            "error_rate": (error_count / request_count * 100) if request_count > 0 else 0,
            "memory_usage": "Not implemented",  # Could add psutil for real metrics
            "cpu_usage": "Not implemented"
        }
        
        return SystemStatusResponse(
            api_server="healthy",
            cli_system="available" if CLI_AVAILABLE else "partial",
            database="configured" if env_validation["checks"].get("environment_variables") == "✅ PASS" else "not_configured",
            environment_validation=env_validation["checks"],
            metrics=metrics
        )
    except Exception as e:
        return APIErrorHandler.handle_general_error(e)


@app.post("/cli/execute", response_model=CLICommandResponse)
async def execute_cli_command(request: CLICommandRequest):
    """
    Execute CLI command endpoint.
    Advanced level: CLI integration with validation and timeout.
    """
    global request_count
    request_count += 1
    
    start_time = time.time()
    
    try:
        if not CLI_AVAILABLE:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="CLI system not available"
            )
        
        # Validate command (basic security check)
        dangerous_commands = ["rm", "del", "format", "shutdown", "reboot"]
        if any(cmd in request.command.lower() for cmd in dangerous_commands):
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="Command not allowed for security reasons"
            )
        
        # Execute command (mock implementation for now)
        # In real implementation, would use subprocess or CLI integration
        execution_time = time.time() - start_time
        
        args_str = ' '.join(request.args) if request.args else ""
        
        return CLICommandResponse(
            success=True,
            output=f"Mock execution of: {request.command} {args_str}",
            error=None,
            execution_time=execution_time,
            command=request.command
        )
        
    except HTTPException:
        raise
    except Exception as e:
        global error_count
        error_count += 1
        execution_time = time.time() - start_time
        
        return CLICommandResponse(
            success=False,
            output="",
            error=format_api_error(e),
            execution_time=execution_time,
            command=request.command
        )


@app.get("/test/comprehensive")
async def run_comprehensive_tests():
    """
    Comprehensive testing endpoint.
    Enterprise level: Full system testing and validation.
    """
    global request_count
    request_count += 1
    
    try:
        tester = APIServerTester()
        results = await tester.run_comprehensive_tests()
        
        return JSONResponse(
            status_code=status.HTTP_200_OK,
            content=results
        )
    except Exception as e:
        return APIErrorHandler.handle_general_error(e)


# ============================================================================
# 7. MAIN EXECUTION (with proper resource management)
# ============================================================================

async def main():
    """
    Main execution function following crawl_mcp.py methodology.
    """
    print("🚀 Phase 12.7: API Server Implementation")
    print("Following crawl_mcp.py methodology: Environment validation → Testing → Deployment")
    
    # Step 1: Environment validation first
    print("\n🔍 Step 1: Environment Validation")
    validation_result = validate_api_environment()
    
    if validation_result["valid"]:
        print("✅ Environment validation passed")
    else:
        print("❌ Environment validation failed:")
        for error in validation_result["errors"]:
            print(f"  - {error}")
        return False
    
    # Step 2: Comprehensive testing
    print("\n🧪 Step 2: Comprehensive Testing")
    tester = APIServerTester()
    test_results = await tester.run_comprehensive_tests()
    
    if test_results["overall_success"]:
        print("✅ Testing completed successfully")
    else:
        print(f"⚠️ Testing completed with issues: {test_results['success_rate']:.1f}% success rate")
    
    # Step 3: Server configuration
    print("\n⚙️ Step 3: Server Configuration")
    host = os.getenv("API_HOST", "0.0.0.0")
    port = int(os.getenv("API_PORT", "8000"))
    debug = os.getenv("DEBUG", "false") == "true"
    
    print(f"📊 Server configuration:")
    print(f"  - Host: {host}")
    print(f"  - Port: {port}")
    print(f"  - Debug: {debug}")
    print(f"  - Environment: {os.getenv('ENVIRONMENT', 'development')}")
    
    # Step 4: Start server (if running directly)
    if __name__ == "__main__":
        print("\n🚀 Step 4: Starting API Server")
        print("🎯 API Server ready for deployment")
        
        config = uvicorn.Config(
            app,
            host=host,
            port=port,
            log_level="info" if debug else "warning",
            access_log=debug
        )
        server = uvicorn.Server(config)
        await server.serve()
    
    return True


if __name__ == "__main__":
    asyncio.run(main()) 